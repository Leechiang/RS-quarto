# Week 7 Classification II

## Summary

### Object based image analysis (OBIA)

Object-based image analysis (OBIA) is an advanced analytical method for remote sensing images that identifies ground features by segmenting images into several objects and taking into account their spatial and spectral properties. Common superpixel approaches, such as the SLIC algorithm, may generate representative objects, while software packages like Supercells allow for variable parameter adjustments. OBIA also includes feature extraction and classification steps, which combine average spectral values with other morphological data to classify objects. Furthermore, more advanced technologies, such as SegOptim, can incorporate other algorithms, expanding segmentation and classification possibilities to improve OBIA capability. In summary, OBIA effectively detects land features using object-level analysis and processing, providing critical support for geographical information systems and other domains.

### Sub pixel analysis
When performing subpixel analysis in urban environments, it is critical to consider factors such as pixel mixing, suitable endmember selection, and computing complexity. The V-I-S model simplifies land cover classification, whereas multiple endmember spectral analysis (MESMA) calculates the fraction of each land cover type inside pixels. These methods, which take into account computational resources and spectrum libraries, improve the accuracy and usability of subpixel analysis, allowing for better urban land cover monitoring and mapping. Subpixel analysis is critical in metropolitan environments due to different land cover types and complex spatial distributions, which frequently result in mixed land cover within pixels. It delivers exact land cover data for urban planning, environmental monitoring, and resource management.

### Accuracy assessment
Random Forest is an technique that builds several decision trees and combines them for classification or regression problems. During each tree's training, it reduces overfitting by using random sampling and random feature selection, while evaluating the model's performance with out-of-bag data. Its main advantages include its capacity to handle huge datasets and high-dimensional data, as well as its resilience to noise. Random Forest uses out-of-bag (OOB) error estimation to provide an accurate assessment of model performance without requiring extra validation datasets.

### Practical result

In the practical part, we've use two train test (Random forest). However, the different between them is that the first one is done by ploygons while the other one is done by using pixels. By comparing the result, the one used polygons is with plenty of errors and the accuracy of the model is unacceptable.

![RF polygon](img/屏幕截图%202024-03-13%20191356.jpg)

In contrast, the result by using pixels is more acceptable and reasonable. But the results shows that the accuracy of the model is about 100% which is not as expected. It can be known that overfitting might be occur during RF pixel. In addition, the possible reason that occurring overfitting is that when I get ploygon for different land covers, I try to avoid 5000 elements which is the highest capability for GEE so the polygon might be too small as training data for RF. The pixels from the polygon may not be representative. Moreover, unlike SNAP, when I draw polygons, we got Spectrum Viewer to check which land cover I am choosing but we don't have it in GEE so there might cause some error for training data.

![RF pixel](img/屏幕截图%202024-03-13%20175926.jpg)

## Applications
As it mentioned in the practical result, overfitting might occur when using CART. In order to solve the weakness of CART. Some alternative methods had been developed. For example, Boosted CART is a method for improving decision tree predictions that may be applied to both classification and regression tasks. It generates trees successively, each using information from the previous one and fitting them to modified versions of the original dataset. As a result, Boosted CART excels at handling large datasets and complex trees. Its value is in integrating numerous decision trees to produce forecasts with smaller variance, hence overcoming CART's constraints.Furthermore, Samir and his colleagues (Samir Barman, Ramasubramanian V, and Mrinmoy Ray, 2019) compared the performances of CART and Boosted CART with the same data from agricultural ergonomics. They found out that in terms of classification accuracy, Boosted CART outperforms CART on the same datasets. Moreover, when I was viewing the lecture slides, a graph caught me:

![RF pixel](img/屏幕截图 2024-03-16 161025.jpg)
The graph shows the comparisons of different machine learning classification algorithms. From the graph, it can be inferred that when comparing with RF, CART has lower accuracy, but it owns higher interpretability. When I was confusing what makes the difference between accuracy and interpretability, a research solved my question. In the research (Anish Kumar, Sanjeev Sinha, and Samir Saurav, 2023), they've investigated the possibilities of stabilising clayey soil with cement and fly ash to strengthen the subgrade pavement layer with RF, multiple regression and CART. The following table shows the result of R square:

![RF pixel](img/屏幕截图 2024-03-16 163046.jpg)
It can be noticed that CART owns the highest R squared result among three algorithms. It is might because that the topic of this research is try to explain the relationship between unconfined compressive strength (UCS) and nonlinear relationships with curing time and binder content.In contrast of classification, which is better with RF because RF may provide higher accuracy.

## Reflections
Once again, GEE is a very powerful tool. I couldn't imagine how time consuming we do remote sensed data classification in R. Moreover, CART and RF are very interesting because it can be used in many different fields, we also learnt about them in Data science module but in Data science we focused more on regression but classification in this module. For me, as it mentioned in application, it is important to choose the right machine learning algorithm because all of them can be better at accuracy and interpretability.However, further learning should be applied because it occurred overfitting when I was doing the practical though I've redraw my polygons for severral times, the accuracy results show 100%.

## Reference
Samir Barman, Ramasubramanian V, and Mrinmoy Ray (2019) ‘An application of Boosted Classification and Regression Trees  (CART) in agricultural ergonomics’.

Anish Kumar, Sanjeev Sinha, and Samir Saurav (2023) ‘Random forest, CART, and MLR‑based predictive model for unconfined  compressive strength of cement reinforced clayey soil: a comparative  analysis’.
